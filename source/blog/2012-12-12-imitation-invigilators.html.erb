---
layout: post
title: Imitation Invigilators
date: '2012-12-12T07:00:00+00:00'
tags:
- future
- computer based testing
- learning
- suggestion
- assessment
- education
- testing online
- improvements
tumblr_url: http://charlieegan3.tumblr.com/post/46786019696/imitation-invigilators
---
<p>At school, and now university, it seems trendy to have lower level assessments sat via <a href="http://en.wikipedia.org/wiki/E-assessment" target="_blank">computer</a> - students like it for the instant results and teachers <strong>love</strong> the absence of any marking. While computer based testing can be handy, and has definite potential, it currently has some very apparent short-comings.</p>
<p>There is really one type of question available: multiple choice. Any other question types can become very ambiguous and extremely challenging to mark (automatically). Take the question: <em>“What is the most demanding user interface on system resources?”</em> as an example. Variations on the correct answer are multiple: <em>Graphical, Graphical UI, Graphical Interface, Graphical User Interface</em> and so on. Now imagine that with the common spelling mistakes or case changes and you’ve got a marking nightmare on your hands. Multiple choice it is then…</p>
<p>This is a problem though, there exists fundamental restrictions on what you can ask with multiple choice. You might think that <em>‘complete the sentences’</em>would work but candidates still pick up more marks one their own answer than completing a given one. This would suggest that people need to explain things in their own words to fully represent their understanding. This makes it challenging to ask anything other than maths related questions, and even then there are problems.</p>
<p>With maths though the issues aren’t as apparent and lurk behind the questions themselves. You can’t have answers that are obviously wrong, why even bother putting them in? You also want to try and stop people from just guessing. This means that you have lots of plausible answers with penalty for getting the wrong one. Lets assume we have a candidate who doesn’t guess and forgets one step in a five step question - they’ve now had marks subtracted, fallen prey to the guesser traps. Even when they did 80% of the question correct - surely that just isn’t fair?</p>
<p>While I don’t like to be the pessimist, but we’ve a long way to go. To ask the questions required to fully test a candidate’s understanding we’d be looking to some form of AI marker and that’s certainly quite a long way off.</p>
<p><strong>-charlie out-</strong></p>